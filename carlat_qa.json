{
  "id": "93260946-b787-4891-9299-97ae97494911",
  "data": {
    "nodes": [
      {
        "id": "ChatOpenAI-uFXiP",
        "type": "genericNode",
        "position": {
          "x": 308.0143526027514,
          "y": -35.11249923706055
        },
        "data": {
          "type": "ChatOpenAI",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, Union\n\nfrom langchain.llms import BaseLLM\nfrom langchain_community.chat_models.openai import ChatOpenAI\n\nfrom langflow import CustomComponent\nfrom langflow.field_typing import BaseLanguageModel, NestedDict\n\n\nclass ChatOpenAIComponent(CustomComponent):\n    display_name = \"ChatOpenAI\"\n    description = \"`OpenAI` Chat large language models API.\"\n\n    def build_config(self):\n        return {\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"field_type\": \"int\",\n                \"advanced\": False,\n                \"required\": False,\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"field_type\": \"NestedDict\",\n                \"advanced\": True,\n                \"required\": False,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"options\": [\n                    \"gpt-4-turbo-preview\",\n                    \"gpt-4-0125-preview\",\n                    \"gpt-4-1106-preview\",\n                    \"gpt-4-vision-preview\",\n                    \"gpt-3.5-turbo-0125\",\n                    \"gpt-3.5-turbo-1106\",\n                ],\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"advanced\": False,\n                \"required\": False,\n                \"value\": 0.7,\n            },\n        }\n\n    def build(\n        self,\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        model_name: str = \"gpt-4-1106-preview\",\n        openai_api_base: Optional[str] = None,\n        openai_api_key: Optional[str] = None,\n        temperature: float = 0.7,\n    ) -> Union[BaseLanguageModel, BaseLLM]:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        return ChatOpenAI(\n            max_tokens=max_tokens,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=openai_api_key,\n            temperature=temperature,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "max_tokens": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "4096",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "model_kwargs": {
                "type": "NestedDict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": {},
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "model_name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "gpt-4-1106-preview",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "gpt-4-turbo-preview",
                  "gpt-4-0125-preview",
                  "gpt-4-1106-preview",
                  "gpt-4-vision-preview",
                  "gpt-3.5-turbo-0125",
                  "gpt-3.5-turbo-1106"
                ],
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "openai_api_base": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": false,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": true
              },
              "openai_api_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "openai_api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true,
                "value": ""
              },
              "temperature": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.07,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "`OpenAI` Chat large language models API.",
            "base_classes": [
              "BaseLanguageModel",
              "BaseLLM",
              "BaseLanguageModel"
            ],
            "display_name": "ChatOpenAI",
            "documentation": "",
            "custom_fields": {
              "max_tokens": null,
              "model_kwargs": null,
              "model_name": null,
              "openai_api_base": null,
              "openai_api_key": null,
              "temperature": null
            },
            "output_types": [
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "ChatOpenAI-uFXiP"
        },
        "selected": true,
        "width": 384,
        "height": 728,
        "dragging": false
      },
      {
        "id": "LLMChain-hK3NU",
        "type": "genericNode",
        "position": {
          "x": 821.465777970347,
          "y": 446.69611179015146
        },
        "data": {
          "type": "LLMChain",
          "node": {
            "template": {
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "memory": {
                "type": "BaseMemory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "BasePromptTemplate",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "prompt",
                "display_name": "Prompt",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Callable, Optional, Union\n\nfrom langchain.chains import LLMChain\n\nfrom langflow import CustomComponent\nfrom langflow.field_typing import (\n    BaseLanguageModel,\n    BaseMemory,\n    BasePromptTemplate,\n    Chain,\n    Document\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable, LLMChain]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Chain to run queries against LLMs",
            "base_classes": [
              "Chain",
              "Callable",
              "Chain",
              "LLMChain"
            ],
            "display_name": "LLMChain",
            "documentation": "",
            "custom_fields": {
              "prompt": null,
              "llm": null,
              "memory": null
            },
            "output_types": [
              "Chain",
              "Callable",
              "LLMChain"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "LLMChain-hK3NU",
          "description": "Chain to run queries against LLMs",
          "display_name": "LLMChain"
        },
        "selected": false,
        "width": 384,
        "height": 424
      },
      {
        "id": "PromptTemplate-metno",
        "type": "genericNode",
        "position": {
          "x": 357.2978641241283,
          "y": 872.5684614535246
        },
        "data": {
          "type": "PromptTemplate",
          "node": {
            "template": {
              "output_parser": {
                "type": "BaseOutputParser",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "output_parser",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_types": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_types",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_variables": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true,
                "value": [
                  "quotes"
                ]
              },
              "metadata": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "metadata",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "name",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "partial_variables": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "partial_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "tags": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "tags",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "template": {
                "type": "prompt",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "fileTypes": [],
                "password": false,
                "name": "template",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true,
                "value": "You are an expert editor for a psychiatric publication. You are editing a document with an expert in a specific field of psychiatric treatment. Please do as you are asked to do so. Do not add anything from yourself.\nFor the given topic and  the extracted quotes, generate 1 to 2 well-worded comprehensive question and answer pairs from those quotes. Do not mention the name of the interviewers or interviewee in the question answer pairs. The answers should be of 200 words for each of the questions generated from the quotes.\nMention the topic name first before generating the question-answer pairs. \n\n\n\nUser: {quotes}\nAssistant:"
              },
              "template_format": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "value": "f-string",
                "fileTypes": [],
                "password": false,
                "name": "template_format",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "validate_template": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "password": false,
                "name": "validate_template",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "PromptTemplate",
              "quotes": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "quotes",
                "display_name": "quotes",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "title_case": true
              }
            },
            "description": "A prompt template for a language model.",
            "icon": null,
            "base_classes": [
              "BasePromptTemplate",
              "PromptTemplate",
              "StringPromptTemplate"
            ],
            "name": "",
            "display_name": "PromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/",
            "custom_fields": {
              "": [
                "quotes"
              ]
            },
            "output_types": [],
            "full_path": null,
            "field_formatters": {},
            "beta": false,
            "error": null
          },
          "id": "PromptTemplate-metno",
          "description": "A prompt template for a language model.",
          "display_name": "PromptTemplate"
        },
        "selected": false,
        "width": 384,
        "height": 374,
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "ChatOpenAI-uFXiP",
        "target": "LLMChain-hK3NU",
        "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ,œBaseLanguageModelœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-uFXiPœ}",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-hK3NUœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "id": "reactflow__edge-ChatOpenAI-uFXiP{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ,œBaseLanguageModelœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-uFXiPœ}-LLMChain-hK3NU{œfieldNameœ:œllmœ,œidœ:œLLMChain-hK3NUœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "LLMChain-hK3NU",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel",
              "BaseLLM",
              "BaseLanguageModel"
            ],
            "dataType": "ChatOpenAI",
            "id": "ChatOpenAI-uFXiP"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "selected": false
      },
      {
        "source": "PromptTemplate-metno",
        "target": "LLMChain-hK3NU",
        "sourceHandle": "{œbaseClassesœ:[œBasePromptTemplateœ,œPromptTemplateœ,œStringPromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-metnoœ}",
        "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-hK3NUœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
        "id": "reactflow__edge-PromptTemplate-metno{œbaseClassesœ:[œBasePromptTemplateœ,œPromptTemplateœ,œStringPromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-metnoœ}-LLMChain-hK3NU{œfieldNameœ:œpromptœ,œidœ:œLLMChain-hK3NUœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "prompt",
            "id": "LLMChain-hK3NU",
            "inputTypes": null,
            "type": "BasePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "BasePromptTemplate",
              "PromptTemplate",
              "StringPromptTemplate"
            ],
            "dataType": "PromptTemplate",
            "id": "PromptTemplate-metno"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "selected": false
      }
    ],
    "viewport": {
      "x": 423.6952774979258,
      "y": 13.123496798996143,
      "zoom": 0.45899165751675525
    }
  },
  "description": "Powerful Prompts, Perfectly Positioned.",
  "name": "carlat_qa",
  "last_tested_version": "",
  "is_component": false
}